{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  YAGO3-10\n",
      "stored_model:  stored_models/TransE_YAGO3-10.pt\n",
      "filtered_ranks:  YAGO3-10/TransE_filtered_ranks.csv\n"
     ]
    }
   ],
   "source": [
    "#in case of single execution of cell\n",
    "dataset = \"YAGO3-10\"\n",
    "stored_model = f\"stored_models/TransE_{dataset}.pt\"\n",
    "filtered_ranks = f\"{dataset}/TransE_filtered_ranks.csv\"\n",
    "\n",
    "print(\"dataset: \", dataset)\n",
    "print(\"stored_model: \", stored_model)\n",
    "print(\"filtered_ranks: \", filtered_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stored_model:  stored_models/TransE_YAGO3-10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Meike\\code\\Kelpie_yago\\scripts\\transe\\train.py\", line 13, in <module>\n",
      "    from link_prediction.evaluation.evaluation import Evaluator\n",
      "  File \"C:\\Users\\Meike\\code\\Kelpie_yago\\link_prediction\\evaluation\\evaluation.py\", line 6, in <module>\n",
      "    from link_prediction.models.transe import TransE\n",
      "  File \"C:\\Users\\Meike\\code\\Kelpie_yago\\link_prediction\\models\\transe.py\", line 10, in <module>\n",
      "    from kelpie_dataset import KelpieDataset\n",
      "ModuleNotFoundError: No module named 'kelpie_dataset'\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "# needs: dataset folder with train.txt, test.txt, valid.txt\n",
    "\n",
    "!python scripts/transe/train.py --dataset $dataset --max_epochs 100 --batch_size 2048 --learning_rate 0.0001 --dimension 200 --margin 5 --negative_samples_ratio 10 --regularizer_weight 50.0 --valid 20 --verbose False\n",
    "\n",
    "# produces: stored_models/TransE_{dataset}.pt   # stored model file\n",
    "#           outputs/<date>/_01_train_py.csv     # logging data\n",
    "#           outputs/<date>/_02_training_stats.csv \n",
    "\n",
    "stored_model = f\"stored_models/TransE_{dataset}.pt\"\n",
    "print(\"stored_model: \", stored_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.py\n",
    "# needs: dataset folder with train.txt, test.txt, valid.txt\n",
    "#        <stored_model>.pt\n",
    "\n",
    "!python scripts/transe/test.py --dataset $dataset --dimension 200 --learning_rate 0.001 --model_path $stored_model\n",
    "\n",
    "# produces: data/<dataset>/filtered_ranks.csv       # same as file #4 but more accessible\n",
    "#           outputs/<date>/_03_test_py.txt           # logging data\n",
    "#           outputs/<date>/_04_filtered_ranks.csv    # prediction evaluation\n",
    "#           outputs/<date>/_05_filtered_details.csv  # mor extensive evaluation\n",
    "\n",
    "filtered_ranks = f\"{dataset}/TransE_filtered_ranks.csv\"\n",
    "print(\"filtered_ranks: \", filtered_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ---------- complex ------------------#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"FR_Reduced_2K\"\n",
    "\n",
    "!python scripts/complex/train.py --dataset $dataset --optimizer Adagrad --max_epochs 50 --dimension 1000 --batch_size 1000 --learning_rate 0.1 --valid 10 --reg 5e-3\n",
    "\n",
    "\n",
    "stored_model = f\"stored_models/ComplEx_{dataset}.pt\"\n",
    "print(\"stored_model: \", stored_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/complex/test.py --dataset $dataset --dimension 1000 --learning_rate 0.1 --model_path $stored_model\n",
    "\n",
    "input_facts = f\"{dataset}/ComplEx_filtered_ranks.csv\"\n",
    "print(\"filtered_ranks: \", filtered_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_input_facts\n",
    "\n",
    "input_facts_file = f\"TransE_{dataset}\".lower()\n",
    "seeds = range(0,10)\n",
    "input_facts = extract_input_facts(source_file=filtered_ranks, output_file=input_facts_file, min_rank=1, mode=\"RND\", seeds=[42], n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain.py - necessary - random - rules_heuristic_frequency\n",
    "\n",
    "!python scripts/complex/explain.py --dataset \"FR_Reduced_2K\" --model_path $stored_model --facts_to_explain_path $input_facts --mode necessary --rules_file $rules_file --second_rules_file $editorial_rules --builder \"rules_heuristic_frequency_optimai\" --verbose False\n",
    "\n",
    "facts_to_verify = f\"data/{dataset}/output.csv\"     # taken from previous output\n",
    "\n",
    "!python scripts/transe/verify_explanations.py --dataset $dataset --model_path $stored_model --dimension 200 --batch_size 1024 --max_epochs 200 --learning_rate 0.01 --reg 50 --mode necessary --facts_to_verify_path $facts_to_verify"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
